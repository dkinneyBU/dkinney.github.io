<!DOCTYPE HTML>
<html><head></head><body><h2 id="are-we-alone">Are we alone?</h2>
<blockquote>
<p>Whether life exists beyond Earth is one of the most profound questions of all time. The answer will change us forever, whether it reveals a universe rich with life, one in which life is rare and fragile, or even a universe in which we can find no other life at all.</p>
</blockquote>
<p>Source: https://exoplanets.nasa.gov/what-is-an-exoplanet/overview/</p>
<p>For this project, I attempt to see if I can train a Machine Learning model to predict whether or not an astral object might be an exoplanet.</p>
<p><a href="https://dkinneyBU.github.io/papers/Predicting%20Exoplanets.docx"><img src="https://img.shields.io/badge/Word-white%20paper-2B579A?logo=Microsoft%20Word"></a></p>
<p><a href="https://dkinneyBU.github.io/presentations/Climate%20Change.pptx"><img src="https://img.shields.io/badge/PowerPoint-Presentation-B7472A?logo=Microsoft%20PowerPoint"></a></p>
<div class="figure">
<img src="https://user-images.githubusercontent.com/43932354/120625299-8f342b80-c42f-11eb-891c-7a82cbd4319a.png" alt="image"><p class="caption">image</p>
</div>
<p>Image credit: NASA/JPL-Caltech/Lizbeth B. De La Torre</p>
<p>Exoplanets are planets that orbit around a star, as in our solar system. These bodies are very hard to see directly with telescopes since they are hidden by the bright glare of the stars they orbit. The Kepler Objects of Interest (KOI) dataset contains various measurements of transit, in addition to many others that aid in identifying exoplanets. In 2009, NASA launched the Kepler spacecraft to search for exoplanets. Kepler looked for planets in a wide range of sizes and orbits that circled around stars of varied size and temperature. [2] The Kepler spacecraft detected exoplanets using the transit method. As a planet passes (transits) in front of a star, it blocks out a bit of the star’s light. By observing the stars’ change in brightness astronomers can figure out the size of the orbiting planet as well as how far away it is from the star. Further, this data then aids in calculating the planet’s temperature, and the chances that it may contain liquid water—<em>the stuff of life</em>…</p>
<p><img src="https://user-images.githubusercontent.com/43932354/120625646-ea661e00-c42f-11eb-86d4-5b6e96986169.png" alt="image"><br>Source: https://spaceplace.nasa.gov/all-about-exoplanets/en/</p>
<p>The <a href="https://exoplanetarchive.ipac.caltech.edu/index.html">NASA Exoplanet Archive</a> is an online astronomical exoplanet and stellar catalog and data service that collates and cross-correlates astronomical data and information on exoplanets and their host stars. As this data is used by astronomers to arrive at whether an object is an exoplanet, it follows that it is likely a Machine Learning model can be developed to make predictions based on the same data.</p>
<h4 id="modeling">Modeling</h4>
<p>A baseline model was established by training a <code>Random Forest Classifier</code>, randomly assigning 1,000 estimators. The function containing the model also applied a <code>StandardScaler</code> to standardize the data prior to model fitting. This resulted in an accuracy score of 86%.</p>
<table>
<thead>
<tr class="header">
<th align="left">Measure</th>
<th align="left">Precision</th>
<th align="left">Recall</th>
<th align="left">F1 score</th>
<th align="left">Support</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Candidate</td>
<td align="left">0.78</td>
<td align="left">0.66</td>
<td align="left">0.71</td>
<td align="left">601</td>
</tr>
<tr class="even">
<td align="left">Confirmed</td>
<td align="left">0.86</td>
<td align="left">0.87</td>
<td align="left">0.87</td>
<td align="left">600</td>
</tr>
<tr class="odd">
<td align="left">False Positive</td>
<td align="left">0.89</td>
<td align="left">0.96</td>
<td align="left">0.93</td>
<td align="left">1190</td>
</tr>
<tr class="even">
<td align="left">Accuracy</td>
<td align="left"></td>
<td align="left"></td>
<td align="left">0.86</td>
<td align="left">2391</td>
</tr>
<tr class="odd">
<td align="left">Macro avg</td>
<td align="left">0.85</td>
<td align="left">0.83</td>
<td align="left">0.84</td>
<td align="left">2391</td>
</tr>
<tr class="even">
<td align="left">Weighted avg</td>
<td align="left">0.86</td>
<td align="left">0.86</td>
<td align="left">0.86</td>
<td align="left">2391</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr class="header">
<th align="left">Actual</th>
<th align="left">Predicted Candidate</th>
<th align="left">Predicted Confirmed</th>
<th align="left">Predicted False Positive</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Candidate</td>
<td align="left">1104</td>
<td align="left">289</td>
<td align="left">372</td>
</tr>
<tr class="even">
<td align="left">Confirmed</td>
<td align="left">198</td>
<td align="left">1517</td>
<td align="left">43</td>
</tr>
<tr class="odd">
<td align="left">False Positive</td>
<td align="left">163</td>
<td align="left">7</td>
<td align="left">3480</td>
</tr>
</tbody>
</table>
<div class="figure">
<img src="https://user-images.githubusercontent.com/43932354/120625775-036ecf00-c430-11eb-80a4-c8cc2944d370.png" alt="image"><p class="caption">image</p>
</div>
<p>This was followed by performing a randomized search by leveraging a <code>RandomizedSearchCV model</code> selector. Interestingly, this did not result in an improvement in accuracy.</p>
<p>The eight categorical variables that were dropped were either informational (url paths, transit model used) or were predominately one value. As an example, “fittype” was one of three values, such as Least Mean Squares. Roughly 90% of the values in this observation were the same value. A <code>StandardScaler</code> was employed rather than a min/max scaler (normalization). Standardization does not bind the variables to a specific range, and some of the variables had an extreme range. As one example, the minimum value for <code>koi_period</code> was .24, and the maximum value was 129,995. I did look at these extreme values and decided they were valid for predicting false positives; therefore I did not want to exclude them. Standardization is much less affected by outliers. I originally had hoped to train a model on the subsets based on categories, but ran out of time. I feel this is still worth pursuing. If one of the subsets results in better accuracy than the the entire subset, less observational data will be required to predict object disposition. Lastly, other models were evaluated (<code>SVM, AdaBoost, XGBoost, TPOT</code>) but the original <code>Random Forest Classifier</code> still resulted in the best results.</p>
<h4 id="conclusions">Conclusions</h4>
<p>While 86% accuracy is not exemplary, that was achieved with a simple baseline model. I am confident greater accuracy is possible, either by fine-tuning the hyperparameters for the Random Forest Classifier, or by training against a larger dataset, if one becomes available. Given that Machine Learning algorithms can process data faster than humans by an order of magnitude, deployment of such a model that can classify observations of the trillions of solar objects present in the observable universe with blinding speed will free up astronomers for more creative endeavors; one area where humans still dominate.</p>
<p><strong>References</strong></p>
<p>[1] NASA Exoplanet Archive – NASA Exoplanet Science Institute https://exoplanetarchive.ipac.caltech.edu/index.html<br>[2] What Is an Exoplanet? | NASA Space Place – NASA Science for Kids<br>[3] Overview | What is an Exoplanet? – Exoplanet Exploration: Planets Beyond our Solar System (nasa.gov)</p>
</body></html>